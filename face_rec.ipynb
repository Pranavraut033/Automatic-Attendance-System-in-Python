{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "import face_recognition\n",
    "from imutils import paths\n",
    "from collections import Counter\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "FACE_CASCADE = \"classifier/haarcascade_frontalface_default.xml\"\n",
    "IMG_SIZE = 128\n",
    "\n",
    "TRAINING_DATASET = 'dataset_training'\n",
    "TESTING_DATASET = 'dataset_testing'\n",
    "MODEL_NAME = 'model_encodings.pickle'\n",
    "\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "FACE_CLASSIFIER = cv2.CascadeClassifier(FACE_CASCADE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the paths to the input images in our dataset\n",
    "print(\"[INFO] fetching images...\")\n",
    "image_paths = list(paths.list_images(TRAINING_DATASET))\n",
    "\n",
    "# initialize the list of known encodings and known names\n",
    "knownEncodings = []\n",
    "knownNames = []\n",
    "\n",
    "# loop over the image paths\n",
    "num_images = len(image_paths)\n",
    "for (i, image_path) in enumerate(image_paths):\n",
    "    # extract the person name from the image path\n",
    "    name = image_path.split(os.path.sep)[-2]\n",
    "    print(\"[INFO] processing image (%s) %d/%d...\" %\n",
    "          (name, i + 1, num_images), end=\"\\r\")\n",
    "\n",
    "    # load the input image and convert it from RGB (OpenCV ordering)\n",
    "    # to dlib ordering (RGB)\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    # detect the (x, y)-coordinates of the bounding boxes\n",
    "    # corresponding to each face in the input image\n",
    "    boxes = face_recognition.face_locations(image, model='cnn')\n",
    "\n",
    "    # compute the facial embedding for the face\n",
    "    encodings = face_recognition.face_encodings(image, boxes)\n",
    "\n",
    "    # loop over the encodings\n",
    "    for encoding in encodings:\n",
    "        # add each encoding + name to our set of known names and\n",
    "        # encodings\n",
    "        knownEncodings.append(encoding)\n",
    "        knownNames.append(name)\n",
    "\n",
    "# dump the facial encodings + names to disk\n",
    "print(\"\\n[INFO] serializing encodings...\")\n",
    "data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
    "f = open(MODEL_NAME, \"wb\")\n",
    "f.write(pickle.dumps(data))\n",
    "f.close()\n",
    "print(\"[INFO] DONE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the known faces and embeddings\n",
    "print(\"[INFO] loading encodings...\")\n",
    "data = pickle.loads(open(MODEL_NAME, \"rb\").read())\n",
    "\n",
    "print(\"[INFO] recognizing faces...\")\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH , 1280)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT  , 720)\n",
    "# cam.set(3, 1280)\n",
    "\n",
    "# cam.set(4, 1024)\n",
    "\n",
    "cv2.namedWindow(\"recognize faces\")\n",
    "\n",
    "num_names = Counter(data['names'])\n",
    "\n",
    "while True:\n",
    "    ret, org = cam.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    k = cv2.waitKey(1)\n",
    "    \n",
    "    cv2.imshow(\"recognize faces\", org)\n",
    "\n",
    "    if k%256 == 27:\n",
    "        print(\"\\nEscape hit, closing...\")\n",
    "        break\n",
    "\n",
    "    # load the input image and convert it from BGR to RGB\n",
    "\n",
    "    # detect the (x, y)-coordinates of the bounding boxes corresponding\n",
    "    # to each face in the input image, then compute the facial embeddings\n",
    "    # for each face \n",
    "    faces = FACE_CLASSIFIER.detectMultiScale(org)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    for (i, f) in enumerate(faces):\n",
    "        x, y, w, h = [ v for v in f ]\n",
    "\n",
    "        sub_face = org[y : y+h+15, x : x + w + 15]\n",
    "#         cv2.imshow(str(i), sub_face)\n",
    "\n",
    "        image = cv2.resize(sub_face, (IMG_SIZE,IMG_SIZE))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        boxes = face_recognition.face_locations(image, model='hop')\n",
    "        encodings = face_recognition.face_encodings(image, boxes)\n",
    "\n",
    "        names = []\n",
    "        boxes = []\n",
    "        # loop over the facial embeddings\n",
    "        for encoding in encodings:\n",
    "            # attempt to match each face in the input image to our known\n",
    "            # encodings\n",
    "            matches = face_recognition.compare_faces(data[\"encodings\"], encoding)\n",
    "            num_prop = 0\n",
    "            # check to see if we have found a match\n",
    "            if True in matches:\n",
    "                # find the indexes of all matched faces then initialize a\n",
    "                # dictionary to count the total number of times each face\n",
    "                # was matched\n",
    "                matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "                counts = {}\n",
    "                # loop over the matched indexes and maintain a count for\n",
    "                # each recognized face face\n",
    "                for i in matchedIdxs:\n",
    "                    name = data[\"names\"][i]\n",
    "                    counts[name] = counts.get(name, 0) + 1\n",
    "\n",
    "                # determine the recognized face with the largest number of\n",
    "                # votes (note: in the event of an unlikely tie Python will\n",
    "                # select first entry in the dictionary)\n",
    "                name = max(counts, key=counts.get)\n",
    "                num_prop = counts[name] / num_names[name]\n",
    "                # update the list of names\n",
    "\n",
    "                print(\"[INFO] detected %s with '%f' accuracy ...\" % (name, num_prop))\n",
    "\n",
    "            if(num_prop > 0.85):\n",
    "                print(\"[INFO] Found %s (%f).\" % (name, num_prop))\n",
    "\n",
    "            boxes.append((y, x + w, y + h, x))\n",
    "            names.append(name if num_prop > 0.8 else \"Unknown\")\n",
    "\n",
    "            # loop over the recognized faces\n",
    "            for ((top, right, bottom, left), name) in zip(boxes, names):\n",
    "                # draw the predicted face name on the image\n",
    "                cv2.rectangle(org, (left, top), (right, bottom), (255, 255, 255), 2)\n",
    "                y = top - 15 if top - 15 > 15 else top + 15\n",
    "                cv2.putText(org, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.75, (0, 255, 0), 2)\n",
    "\n",
    "            # show the output image\n",
    "            cv2.imshow(\"recognize faces\", org)\n",
    "\n",
    "cam.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
